# 📚 스터디 템플릿

## 📖 1. 목차를 읽기 전에 든 생각
- 기술적으로 대량의 클릭 이벤트를 실시간으로 처리하고 집계하기 위한 시스템 아키텍처는 어떻게 설계될까?

## 📝 2. 내용 정리
### API 설계
1. 지난 M분 동안 각 ad_id에 발생한 클릭 수 집계
2. 지난 M분 동안 가장 많은 클릭이 발생한 상위 N개 ad_id 목록 반환
3. 다양한 속성을 기준으로 집계 결과를 필터링하는 기능 지원

### 데이터 모델
- 원시 데이터를 저장하는 방안과 집계 결과 데이터만 보관하는 방안의 장단점
    - 원시데이터 장점
        - 데이터 손실 없이 보관
        - 데이터 필터링 및 재계산 지원
    - 원시데이터 단점
        - 막대한 데이터 용량
        - 낮은 질의 성능
    - 집계 데이터 장점
        - 데이터 용량 절감 및 빠른 질의 성능
    - 집계 데이터 단점
        - 데이터 손실, 원본 데이터가 아닌 계산/유도된 데이터를 저장하는 데서 오는 결과

### 올바른 데이터베이스 선택
- 데이터는 어떤모습? 관계형? 문서형? 아님 이진대형?
- 작업 흐름이 읽기 중심인가 쓰기 중심인가? 아니면 둘다인가?
- 트랜잭션을 지원해야 하는가?
- 질의 과정에서 SUM이나 COUNT 같은 온라인 분석 처리 함수를 많이 사용해야하는가?

- 위와 같은 질문을 생각해보는게 좋다.
- 원시데이터 : 질의할 필요가 없지만 기계 학습 엔지니어가 사용자 반응 예측, 관련성 피드백 등을 연구하는 경우에는 유용하다. 
    - 이 설계안은 쓰기 중심 시스템이다. MySQL로도 가능하지만 카산드라나 InfluxDB를 사용하는 것이 좀 더 바람직하다.
    - ORC, 파케이, AVRO 같은 칼럼형 데이터 형식 가운데 하나를 사용하여 아마존 S3에 데이터를 저장하는 방법도 존재한다. 하지만 본 설계안에서는 카산드라를 사용한다.
- 집계 데이터 : 읽기 연산과 쓰기 연산을 둘다 많이 사용한다.

### 비동기 처리
- 동기식 처리는 생산자와 소비자 용량이 항상 같을 수 없으므로 좋지 않다.
- 이 문제를 해결하는 일반적인 방안은 카프카 같은 메시지 큐를 도입하여 생산자와 소비자의 결합을 끊는 것이다.

### 집계 서비스
- 광고 클릭 이벤트를 집계하는 좋은 방안 하나는 맵리듀스 프레임워크를 사용하는 것이다.
- 맵리듀스 프레임워크에 좋은 모델은 유향 비순환 그래프이다.

#### 맵 노드
- 맵 노드는 데이터 출처에서 읽은 데이터를 필터링하고 변환하는 역할을 담당한다.
- 집계 노드가 카프카를 직접 구독하도록 하면 입력 데이터를 정리하거나 정규화해야 하는 경우에 힘들다 그래서 맵노드가 필요하다.
#### 집계 노드
- ad_id별 광고 클릭 이벤트 수를 매 분 메모리에서 집계한다. 맵-집계-리듀스 프로세스는 실제로 맵-리듀스-리듀스 프로세스라고도 할 수 있다.
#### 리듀스 노드
- 모든 `집계` 노드가 산출한 결과를 최종 결과로 축약한다.
- 자기 관점에서 가장 많은 클릭이 발생한 광고 3개를 추려 리듀스 노드로 보낸다
- 이 모델의 중간 데이터는 메모리에 저장될 수 있고, 노드 간 통신은 TCP로 처리할 수도 있고 공유 메모리로 처리할 수도 있다.

### 스트리밍 vs 일괄처리
- 본 설계안은 스트림 처리와 일괄처리 방식 모두 사용한다. 스트림 처리는 데이터를 오는 대로 처리하고 실시간으로 집계된 결과를 생성한다. 일괄처리는 이력 데이터를 백업하기 위해 활용한다.
- 카파 아키텍처는 일괄처리와 스트리밍 처리 경로를 하나로 결합하여 사용한다. 그래서 카파 아키텍처를 따르도록 한다.

#### 데이터 재계산
- 이미 집계한 데이터를 다시 계산해야 하는 경우가 존재한다. 이를 이력 데이터 재처리라고도 부른다
- 버그 발생 시점부터 원시 데이터를 다시 읽어 집계 데이터를 재계산하고 고쳐야 한다.
1. 재계산 서비스는 원시 데이터 저장소에서 데이터를 검색하고 일괄처리 프로세스를 따른다.
2. 추출된 데이터는 전용 집계 서비스로 전송된다.
3. 집계 결과는 두 번째 메시지 큐로 전송되어 집계 결과 데이터베이스에 반영된다.

#### 시간
- 타임스탬프가 필요한데 타임스템프는 이벤트 시각과 처리시각으로 만들어질 수 있다.
- 네트워크 지연이나 비동기적 처리환경때문에 이벤트가 발생한 시각과 처리 시각 사이의 격차는 카질 수 있다.
- 데이터의 정확도는 아주 중요하다. 때문에 이벤트 발생 시각을 사용할 것을 추천한다. 
- 그림 6.13의 문제는 워터마크를 이용해 해결한다. 워터마크는 집계 윈도의 확장으로 본다. 이렇게 하면 집계 결과의 정확도를 높일 수 있다.
- 워터마크는 비즈니스 요구사항에 따라 크기를 다르게 잡는다. 워터마크 구간이 길면 늦게 도착하는 이벤트도 포착할 수 있지만 시스템의 이벤트 처리 시간은 늘어난다.

### 집계 윈도
- 윈도에는 텀블링 윈도, 호핑윈도, 슬라이딩 윈도, 세션 윈도의 네 종류가 존재한다.
- 본 설계안과 관련 있는 텀블링 윈도와 슬라이딩 윈도와 관련이 있고 슬라이딩 윈도는 데이터 스트림을 미끄러져 나아가면서 같은 시간 구간 안에 있는 이벤트를 집계한다.

### 전달 보장
- 정확성과 무결성이 아주 중요하다.
1. 이벤트의 중복 처리를 어떻게 피할 수 있는가?
2. 모든 이벤트의 처리를 어떻게 보장할 수 있는가?
- 카프카와 같은 메시지 큐는 보통 세가지 전달 유형을 지원한다.
- **어떤 전달 방식을 택할 것인가** : 약간의 중복이 괜찮다면 `최소 한 번`이 적절하다. 하지만 본 설계안에서 다루는 시스템은 그렇지 않다. `정확히 한 번`을 권장한다.

#### 데이터 중복 제거
- 집계 도중에 집계 서비스 노드에서 장애가 발생하였고 업스트림 서비스가 이벤트 메시지에 대해 응답을 받지 못하였거나 한 클라이언트가 같은 이벤트를 여러 번 보내는 경우에 데이터가 중복된다. 
- 이 문제를 가장 간단하게 해결하는 방법은 외부 파일 저장소에 오프셋을 기록하는 것이다.
- 데이터 손실을 막으려면 다운스트림에서 집계 결과 수신 확인 응답을 받은 후에 오프셋을 저장해야한다.

### 시스템 규모 확장
#### 메시지 큐의 규모 확장
- 생산자 : 생산자 인스턴스 수에는 제한을 두지 않으므로 확장성은 쉽게 달성할 수 있다.
- 소비자 : 소비자 그룹 내의 재조정 매커니즘은 노드 추가/삭제를 통해 그 규모를 쉽게 조정할 수 있도록 한다.

#### 브로커
- 해시 키 : 같은 ad_id를 갖는 이벤트를 같은 카프카 파티션에 저장하기 위해 ad_id를 해시 키로 사용한다. 
- 파티션의 수 : 파티션의 수가 변하면 같은 ad_id를 갖는 이벤트가 다른 파티션에 기록되는 일이 생길 수 있다. 파티션 수가 동적으로 늘어나는 일은 피하는 것이 좋다.
- 토픽의 물리적 샤딩 : 데이터를 여러 토픽으로 나누면 대역폭을 높일 수 있다. 하지만 복잡성이 증가하고 비용이 늘어난다.

#### 집계 서비스의 규모 확장
- 집계 서비스의 규모는 노드 추가/삭제를 통해 수평적으로 조정이 가능하다.
- 대역폭을 높이려면 ad_id마다 별도의 처리 스레드를 두거나 집계 서비스 노드를 아파치 하둡 같은 자원 공급자에 배포하는 방식 두가지가 존재한다.

### 데이터베이스의 규모 확장
- 카산드라는 안정 해시와 유사한 방식으로 수평적인 규모 확장을 기본적으로 지원한다.
- 데이터를 각 노드에 균등하게 분산하고 사본도 적당한 수만큼 만들어 분산한다.
- 수동으로 샤딩을 조정하는 과정은 필요하지 않다.

### 핫스팟 문제
- 다른 서비스나 샤드보다 더 많은 데이터를 수신하는 서비스나 샤드를 핫스팟이라 부른다.

### 결함 내성
- 집계 메모리에서 이루어지므로 집계 노드에 장애가 생기면 집계 결과도 손실된다. 하지만 업스트림 카프카 브로커에서 이벤트를 다시 받아오면 그 숫자를 다시 만들어 낼 수 있다.
- 스냅샷을 이용하면 집계 서비스의 복구 절차가 단순해진다.

### 데이터 모니터링 및 정확성
#### 지속적 모니터링
- 지연시간, 메시지 큐 크기, 집계 노드의 시스템 자원은 지속적인 모니터링이 필요하다.

#### 조정
- 다양한 데이터를 비교하여 데이터 무결성을 보증하는 기법을 말한다.
- 매일 각 파티션에 기록된 클릭 이벤트를 이벤트 발생 시각에 따라 정렬한 결과를 일괄 처리하여 만들어 낸 다음 실시간 집계 결과와 비교해 보는것. 이것이 다양한 방법중 한가지 방법이다.

## 💡 3. 전부 읽고 난 후기
- 실제 시스템 구축 시 고려해야 할 워터마크, 중복 제거, 확장성, 장애 대응 등 다양한 이슈에 대해 다루는 방법을 알게되었다. 
- 실제 회사에서 많이 사용하는 기술인 것 같은데 뜻깊었다.

## ❓ 4. 특별히 궁금했던 부분
- 광고 클릭 이벤트 뿐 아니라 노출, 전환 등 다른 이벤트들도 함께 집계하게 된다면 각 이벤트 타입 별로 별도의 파이트 라인을 구성해야할까?
- 클릭 이벤트에 대한 부정행위 탐지는 어떤 방식으로 적용하는 것이 좋을까?