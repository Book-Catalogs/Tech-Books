# 📚 스터디 템플릿

## 📖 1. 목차를 읽기 전에 든 생각
- 지표 모니터링과 경보에서 중요한 것은 대용량 데이터를 적절히 처리하는데에 있다.
- 이 책은 빌드업이 잘 되어 있으니, 이번 장에서는 분산 메시지 큐를 사용하여 보내어지는 로그를 적절히 보관하고 해당 로그로 하여금 적절하게 경보를 날리는데 있다.
- Grafana만 생각해봐도 여러 회사가 사용하고 있고, 각 회사에서 사용하고 있는 알림 Metric은 정말 수도 없이 많을 것이다. 이를 동기 처리로 하여 처리한다면 서비스는 금방 망가지지 않을까?
- 따라서, 경보를 내보내는데에 있어서도 분산 메시지 큐를 사용해야 할 것이다. 여러 방식 중에서도 최소 한 번만 만족하는 수준으로 두면 되지 않을까?

## 📝 2. 내용 정리
### 비기능 요구사항
- 규모 확장성 : 늘어나는 지표 수와 경보의 양에 맞게 적절하게 확장
- 낮은 응답 지연 : 경보 혹은 질의에 대해서 낮은 Latency 보장
- 안정성 : 경보가 누락되면 안된다.
- 유연성 : 여러 기술들이 계속 발전하기 때문에 유연하게 변경 가능해야 한다.

### 지표 모니터링 경보 시스템 주요 컴포넌트
- 데이터 수집 : 여러 출처로부터 지표 데이터 수집
- 데이터 전송 : 지표 데이터를 지표 모니터링 시스템으로 전송
- 데이터 저장소 : 전송되어 오는 데이터를 정리하고 저장
- 경보 : 데이터를 분석하고 이상 징후를 감지하여 경보를 발생
- 시각화 : 데이터를 차트나 그래프 등으로 제공

### 데이터 모델
- 시계열 데이터를 저장
**시계열 데이터** : 시간 순서에 따라 기록된 데이터
- 시계열 데이터 포맷
  - 시계열 데이터는 **행 프로토콜**을 따른다.
> measurement | tag set | field set | timestamp
```bash
weather,location=us-midwest temperature=82 1465839830100400200
  |    -------------------- --------------  |
  |             |             |             |
  |             |             |             |
+-----------+--------+-+---------+-+---------+
|measurement|,tag_set| |field_set| |timestamp|
+-----------+--------+-+---------+-+---------+
```
### 데이터 접근 패턴
- 읽기 부하는 일시적으로만 치솟는(spiky) 패턴
- 쓰기 부하는 지속적으로 많은 양의 쓰기 발생.

### 데이터 저장소 시스템
관계형 데이터베이스나 일반적인 NO-SQL은 시계열 데이터를 저장하고 질의하는데 적합하지 않음. 특히, 질의는 큰 문제가 있다.
시계열 데이터만을 질의하기 위해서 존재하는 데이터 저장소가 있음 **EX) InfluxDB, Prometheus**
태그에 대한 카디널리티가 낮아야 함. -> 이건 관계형 데이터베이스의 인덱스 생성기준과도 일치. **카디널리티와 중복도의 관계는 상반 관계**

### 풀 vs 푸시 모델

| 항목        | 풀 모델 (Pull Model) | 푸시 모델 (Push Model) |
|------------|---------------------|---------------------|
| 손쉬운 디버깅 | 엔드포인트를 강제하므로 언제든 지표 데이터를 볼 수 있다. | X |
| 상태 진단 | 애플리케이션이 응답하지 않으면 해당 서버에 문제가 있음을 바로 알 수 있음. | 지표 수집기가 지표를 받지 못하면 네트워크 장애가 원인인지 서버 장애가 원인인지 알 수 없음. |
| 일관성 | 작업을 처리하고 지표 수집기에서 데이터를 가져가기 전에 서비스가 종료되면 가져갈 수 없음. | 요청하고 가져오기 때문에 늘 가져올 수 있음. |
| 네트워크 | 엔드포인트가 열려있으므로 네트워크 방화벽 구성을 적절하게 해주어야 함. | 내부에서 외부로 보내는 것이므로 늘 받을 수 있다. (에이전트 설치) |
| 성능 | TCP | UDP (손실 가능성 있음) |
| 데이터 신빙성 | 목록이 이미 정의되어 있으므로 신빙성이 있다. | 아무 데이터나 보낼 수 있으므로 자칫하면 이상(Anomaly) 데이터가 있을 수 있다. |

### 데이터 집계 지점
지표 집계는 수집 에이전트 혹은 데이터 수집 파이프라인에서도 가능하다.

#### 수집 에이전트 집계
- 복잡한 질의는 처리가 불가능하여, 카운터 값을 보내는 정도만 가능하다.
#### 데이터 수집 파이프라인 집계
- 데이터 베이스에는 집계 결과만 저장되므로 실제로 기록되는 데이터의 크기는 작아진다. 단, 늦게 도착하는 지표 데이터의 처리는 어려워 정밀도가 유연성이 떨어 질 수 있다.
#### 질의 시에 집계
- 데이터 손실 문제는 없으나 전체 데이터 세트를 대상으로 집계 결과를 계산해야하므로 Latency가 떨어질 수 있다. 

### 저장소 계층 데이터 샘플링
- 기간 단위로 데이터를 샘플링하여, 데이터의 저장 크기를 줄일 수 있다. 집계 쿼리를 사용하여 10초당 -> 30초당 -> 1분당으로 개수를 천천히 ALTER 가능.

### 경보 시스템
- 경보 조건은 접근 속도 향상을 위해 캐시에 보관한다.
- 경보에 대한 처리는 이벤트를 발행해서 소비하도록 한다. 이 때, 지연이 발생하지 않도록 적절하게 확장할 수 있어야 한다.

## 💡 3. 전부 읽고 난 후기
- Prometheus가 DB라는 사실을 처음 알았다. 단순히 쿼리를 집계해주는 시스템인줄 알았는데, Micrometer가 prometheus DB를 연결 할 수 있도록 도와주는거였구나. 역시 코드는 전부 이어져있다. 내가 모르고 있을 뿐..
- 가끔 보면 우리가 자주 사용하는 상용화 된 시스템을 사용할 때, 어떻게 구현을 했을까. 이 시스템에서 고려할 만한 문제점은 무엇이 있을까? 를 생각해보지 않았던 것 같은데 이 책은 그런 생각의 폭을 넓혀준다.
- 길을 지나가다가도 내가 어떤 애플리케이션을 사용하다가도 실제로 해당 문제를 어떻게 해결할 수 있을지. 또는 해당 문제를 내가 어떻게 구현 할 것인지에 대한 생각을 하는 것이 중요하다는 어느 시니어님의 말은 틀린게 없다.

## ❓ 4. 특별히 궁금했던 부분
- 경보 조건을 캐시에 보관을 하게 되는데, 경보 조건 같은 경우는 몇 분에 한 번씩 캐시하는게 좋을까?
- 재시도는 보통 몇 회 정도를 하는게 좋을까? 또 재시도 로직은 어디에 보관하는게 좋을까. 
