# 📚 스터디 템플릿

## 📖 1. 목차를 읽기 전에 든 생각
- 우리 회사에서 하고 있는거라서 그 구조랑 똑같은 설명일지 기대 중
- 직접 담당하신 범석님이 계셔서 다음 스터디에 무한 질문 공세 대기 중, 고려해야 할 점, 실제로 발생했던 문제들
- 클라이언트의 시점 문제에 따른 점핑은 어떻게 방지하지? 이거 저번에 프론트에서 문제 있다고 했었음.

## 📝 2. 내용 정리

### RTB(Real-Time Bidding)  
**DSP(Demand-Side Platform)** 를 이용하여 광고 노출 지면에 입찰하는 방법이며, 해당 거래 절차를 통해 거래한다.
- DSP는 광고 지면(Inventory)를 구매하기 위해서 사용하는 소프트웨어 플랫폼이다.
- 온라인 광고의 핵심 지표는 **CTR(Click-Through Rate, 클릭률), CVR(Conversion Rate, 전환율)** 등이 있다.

### 데이터 모델

#### 원시 데이터
- 광고 아이디, 클라이언트 클릭 시간, user_id, ip, country 등을 적재한다.

#### 집계 결과 데이터
- 광고 필터링을 지원하기 위해서 filter_id 참조를 사용한다. (해당 필터에는 여러 조건들이 나열되어 있다. 이는 coupon 정책에도 주로 사용됨)

#### 원시 데이터 vs 집계 결과 데이터
|INDEX|원시 데이터|집계 결과 데이터|
|---------|----------------------|-----------------|
|장점|원본 데이터를 손실 없이 보관<br> 데이터 필터링 및 재계산 지원|데이터 용량 절감<br> 빠른 질의 성능
|단점|막대한 데이터 용량<br> 낮은 질의 성능|데이터 손실<br> 원본 데이터가 1개의 집계 데이터로 변환 가능|

- 하지만, **둘 다 저장하는 것**을 추천 실제로 해당 데이터로 인해서 집계를 하고 광고비를 추산하기 때문에 데이터에 대한 보증이 가능하며, 데이터가 유실되었을 경우에 대한 복구 가능성도 존재해야 함.
- 하지만, 데이터의 저장을 다루는 저장소는 다르게 사용하는 것이 좋다.
- 오래된 원시 데이터는 cold storage에 보관한다.

### 데이터 베이스 선택
- 전반적으로 쓰기량이 많으므로 쓰기에 좋은 카산드라 DB를 사용하는 것이 좋다.
- 또한, 로그 데이터에 대해서 집계 쿼리를 주로 사용하여 시간 순서로 데이터가 적재되므로 시계열 데이터 저장이 용이한 InfluxDB 혹은 Prometheus를 사용한다.

### 처리 방식
- 동기 방식은 처리 방식에 있어서 확장성이 떨어지므로 좋지 않다. 어떤 한 부분에 대한 장애가 다른 서비스까지 장애가 전파되기 때문이다.
- 따라서, 이벤트를 통한 비동기 방식을 사용한다. 이때, 이벤트 방식을 사용하면 적절하게 파티셔닝을 더 한다거나 소비자 수를 늘려서 조절 할 수 있다. 하지만, 파티셔닝은 한 번 늘리면 다시 줄일 수는 없기에 적절히 고려하여 늘려야 한다.

### 데이터 메시지 처리
- 이벤트 처리는 두 번의 스트림 방식을 거쳐서 진행한다.
<img width="1042" alt="image" src="https://github.com/user-attachments/assets/ac75e1ae-76ba-4b6e-a22e-8159ce2ec97c" />

### 집계 서비스
- 집계 서비스를 진행하기 위해서는 MapReduce 프레임워크를 사용하는 것이 좋다.
- MapReduce는 유방향 비순환 그래프(Directed Acyclic Graph, DAG) 모델을 사용하는 것이 좋다.

#### DAG
- 맵/집계/리듀스 노드 등의 작은 컴퓨팅 단위로 세분화하는 것이다. 각 노드는 한 가지 작업만 처리하며, 처리 결과를 다음 노드에 인계한다.
- 메시지 발행을 통해서 집계하는 경우에는 생성에 대한 제어권이 없는 경우에는 같은 ad_id를 갖는 이벤트가 서로 다른 파티셔닝에 분배 될 수 있다. (ad_id를 해시 키 기준으로 하면 발생 할 수 가 있나?)

### 스트리밍 vs 일괄 처리

#### 스트림 처리
- 데이터를 오는 대로 처리하고 거의 실시간으로 집계된 결과를 생성하는 데 사용한다.

#### 일괄 처리
- 이력 데이터를 백업하기 위해 활용한다.

평상 시에는 실시간으로 데이터를 처리 하기 위하여 스트림 방식으로 데이터를 처리하고, 이후에 데이터의 손실 혹은 오류 등으로 인해서 재 집계 해야하는 경우에는 일괄 처리 방식을 사용한다.
이 두 가지를 분리하면 응집도가 떨어지는데, 이를 한 번에 처리하도록 하는 방식이 'Kappa 아키텍처' 이다.

### 시간
- 집계 시에는 타임 스탬프가 필요하다. 타임 스탬프는 **'이벤트 발생 시각'**, **'처리 시각'** 두 가지가 있다.
- 이벤트 발생 시각 사용 시, 지연 된 이벤트 처리 시각 문제가 있다.
- 처리 시각 사용 시, 집계 결과가 부정확 할 수 있다.
- 비용적인 측면으로 고려해볼 때, 정확도가 더 중요하므로 이벤트 발생 시각을 사용한다.

#### 처리 방식
- 집계 처리를 하기 위해 윈도우 처리 방식을 사용하나, 유실 데이터를 위해 **워터마크 방식**을 사용한다.
- 워터마크의 크기는 비즈니스 요구사항에 따라 달라 질 수 있으며, 실제 데이터 처리 량에 따라서 유연하게 변경되어야 한다.
- 워터마크가 길면 늦게 도착하는 이벤트도 처리 할 수 있지만 처리 시간이 늘어나며, 짧으면 정확도가 떨어지지만 처리 시간이 줄어든다.

### 데이터 중복 제거

#### 클라이언트
- 한 클라이언트가 악의적으로 같은 이벤트를 여러 번 보내는 경우, **광고 사기/위험 제어 컴포넌트**를 통해 중복을 방지한다.

#### 서버
- 집계 서비스 노드에서 장애가 발생했고, 업스트림 서비스가 이벤트 메시지에 대해 응답하지 못했을 때 같은 이벤트를 재 집계 할 수 있다. (최소 한 번 로직으로 인해서)
- 오프셋을 S3에 저장하여 오프셋을 검증하는 방식을 걸칠 수 있으며, 분산 트랜잭션 방식을 통해 공통 커밋 영역에서 장애가 발생하면 보상 트랜잭션 로직을 수행하여 롤백한다.

### 결함 내성
- 카프카 데이터를 원점부터 다시 재생하여 집계하면 시간이 오래 걸리므로, 시스템 상태를 Snapshot으로 저장하고 마지막으로 저장된 상태부터 복구하면 집계 속도를 개선 할 수 있다.

### 지속적인 모니터링
- 지연 시간(Latency) : 데이터를 처리하는 각 단계마다 지연시간이 추가 될 수 있으므로, timestamp를 추적하여 지연 시간 지표를 모니터링 해야한다.
- 메시지 큐 크기 : 메시지 큐에서 토픽에 있는 메시지가 적절하게 빠지고 있는지 확인해야 하므로, 토픽 내의 메시지를 추적해야 한다.
- 집계 노드의 시스템 자원 : OOM이 발생하지 않도록 CPU, JVM, 디스크 지표를 확인해야 한다.

## 💡 3. 전부 읽고 난 후기
- 아.. 어렵다.. 지금까지 읽었던 챕터 중에 제일 어렵다. 이해가 안가는 부분이 한 둘이 아니다.
- 이번에 어려웠던 이유는 분산 메시지 큐에 대한 이해와 새로운 아키텍처의 방식 떄문으로 보인다. 말은 이해가 되는데 이를 어떤 방식으로 구현하지에 대한 의문점들이 너무 많이 떠오른다.

## ❓ 4. 특별히 궁금했던 부분
- 워터마크 방식을 채택하여 정확도를 높이는 집계 방식을 사용한다고 했을 때, 중복되는 데이터는 어떻게 처리 할 것인가. (211p, 그림 6.14)
- 스냅샷은 어디에 저장하는 걸까? 카프카 내부에 있는 건가? 만약에 아니라고 한다면 파일 저장소, DB 저장소 일텐데 이를 불러들이는데 시간이 더 오래 걸릴 수도 있을 듯 한데...
- 더 많은 집계 서비스 노드를 추가해서 발행하고 다시 컨슘하는데 같은 ad_id로 파티셔닝 되어 있는 상황에서 이를 분산해서 집계하고 처리한다면 이는 정확하다고 할 수 있는가?
