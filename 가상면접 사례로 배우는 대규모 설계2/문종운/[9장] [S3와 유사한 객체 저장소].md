# 📚 스터디 템플릿

## 📖 1. 목차를 읽기 전에 든 생각
- 생각해보니 S3에 저장되어있는 파일도 실제 어딘가의 파일 서버에 연결해서 많은 파일들을 보관하여야 한다. 이걸 왜 생각을 못하고 있었을까?
- 파일 서버를 실제 Bucket 별로 어떻게 구분 할 것인가. 정말 대용량의 파일들이 있고 파일 I/O를 빠르게 하기 위해서는 RA(Random Access) 보다 DA(Direct Access)가 가능한 SSD를 사용해야 할 것이다.
- 실제로 명명되어 있는 Bucket과 고유 키 값으로 File Server를 찾아서 할당 받아야 할텐데, Bucket의 키 값을 어떻게 부여 할 것인가? key - value의 탐색이 필요하다.
- 또한, S3에는 이벤트 처리와 스케줄링 처리가 가능한 기능이 있다. ex) 매일 09:00에 해당 bucket에 있는 Files 중 생성 일자가 last weeks인 데이터를 삭제해줘. 이는 어떻게 처리할까? 

## 📝 2. 내용 정리

### 저장소 시스템

#### 블록(block) 저장소
- HDD나 SSD처럼 **서버에 물리적으로 연결되는 형태**의 드라이브이다.
- 네트워크 통신을 통해서 블록 저장소에도 접근이 가능하고, 표준 연결 프로토콜을 통해서 접근 또한 가능하다. **I/O 장치에 어떤 방식으로든 연결하여 애플리케이션 자체에서 접근 가능하도록 하는 형태**이다.

#### 파일(File) 저장소
- 파일 저장소는 블록 저장소보다 더 높은 추상화 단계를 가지고 있는 저장소이다.
- 데이터는 계층 구조의 디렉터리 안에 보관되며 가장 널리 사용되고 있는 저장소이다.
- NFS와 같은 파일 수준의 네트워크 프로토콜을 통해 하나의 저장소를 여러 서버에 동시에 붙일 수 있다. (공유 가능)

#### 객체 저장소
- 파일의 탐색에 대한 목적이 아닌 보관을 목적으로 수평적인 구조로 파일을 보관하는 구조이다.
- 따라서, 탐색 속도는 파일 저장소 혹은 블록 저장소에 비해 떨어진다. 하지만, 성능을 희생한만큼 비용 자체는 적게 든다.

### 객체 저장소 특징

#### 객체 불변성
- 객체 저장소에 보관되는 객체들은 변경이 불가능하다.
- 단, 버저닝을 수정하여 새 버전의 객체로 대체는 가능하다. 즉, 점진적인 수정은 불가능하다.

#### 키-값 저장소
- 데이터를 가져오는 경우에는 해당 객체의 URI를 사용하여 데이터를 가져 올 수 있다.

#### i-node 관점의 데이터 보관
- 보관하고자 하는 객체의 메타 데이터는 별도의 메타 데이터 저장소에 보관하며, 메타 데이터 저장소에 실제 데이터들은 데이터 주소 **pointer**를 사용하여 각각의 실제 데이터를 합쳐서 가지고 온다.
- 이 때, 데이터 저장소에 보관되는 데이터는 늘 불변하며 메타데이터만 변경이 가능하다.

#### 객체의 업로드 과정
최종적으로 데이터가 보관되는 장소는 AWS 자체적으로 구성되어 있는 분산 데이터 스토리지에 각 Disk Node에 보관된다는 것을 전제가 깔려있다.
1. 클라이언트에서 버킷 생성을 요청하는 PUT HTTP 요청을 보내고, IAM은 버킷을 생성 할 수 있는 권한을 가지고 있는지 확인한다.
2. 버킷에 대한 메타데이터를 생성하여 별도의 메타 데이터 저장소에 보관한다. 저장소는 파일 일수도 있고, DBMS에 보관 할 수도 있다. 즉, 내부 구현은 별도의 방식에 따라 달리 보관된다.
3. 클라이언트에서 객체를 생성하기 위한 파일을 보내고, 다시 한 번 파일을 생성 할 수 있는 권한을 가지고 있는지 확인한다.
4. 객체를 생성 할 수 있다면 Object 자체의 바이너리 데이터를 데이터 저장소 노드에 저장한다. 이 때, 데이터 저장소의 UUID 별로 각 데이터 pointer를 보관한다.
5. 마지막으로 생성된 객체의 UUID와 메타 데이터를 메타 데이터 저장소에 보관한다.

#### 객체의 다운로드 과정
객체의 업로드 과정과 유사하게 흘러간다.
1. 클라이언트가 GET 요청을 통해 해당 bucket에 있는 객체의 아이템을 검색하는 질의를 보낸다.
2. IAM은 해당 클라이언트가 READ 권한이 있는지를 확인하며 권한이 있으면 객체의 UUID를 메타데이터 저장소로 부터 가지고 온다. 
3. UUID를 통해 데이터 저장소에 분산되어 있는 데이터들을 가지고 온다.

### 데이터 라우팅 서비스
데이터 노드 서버도 결국 별도의 데이터 노드 서버로 구성이 되어 있다. 해당 데이터 노드 서버 또한 모종의 이유로 서버가 다운 될 가능성이 있기에 이를 확인하여 데이터 보관의 유실이 생기지 않도록 해야 한다.  
별도의 배치 서비스를 호출하여 박동 메시지를 주고 받아 현재 서버가 정상적인 상태인지를 확인한다.  
이 때, 별도의 consensus 프로토콜(ex, Paxos, Raft)를 사용하여 장애를 감내할 수 있도록 데이터 노드의 가용성을 확인하여 동작하도록 한다.

### 가용성과 내구성

#### 데이터 노드
데이터 노드 한 곳에만 데이터를 보관하게 되면 해당 데이터 노드의 서버가 죽었을 경우에는 해당 데이터를 가지고 오지 못하게 된다. 따라서, 데이터의 일관성과 가용성을 위해서 여러 개의 데이터 노드에 분산적으로 데이터를 복제하여 보관한다. 이를 **다중화 그룹** 이라고 부른다.  
이는 마치 디스크 가용성 목적을 위해서 존재하는 RAID 1단계 이상의 방식과 유사하다.  
- 데이터 노드에는 부착된 디스크 드라이브(HDD/SSD)의 수와 각 드라이브에 저장된 데이터의 양을 보관하고 있다.

#### 데이터는 어떻게 저장되는가
데이터를 저장 할 때에는 어떠한 바이너리 데이터를 블록 단위에 저장하며 해당 블록은 디스크가 불륨을 초기화 할 때 결정이 된다. 하지만, 고정된 블록의 매우 작은 데이터가 지속적으로 보관된다면 고정된 크기로 보관되어 있는 데이터 블록이 낭비되게 된다. 즉, 내부 단편화가 많이 발생하게 되며 이로 인해서 외부 단편화 현상 또한 이어져서 생길 수 있는 것이다.

이를 해결하기 위해서는 가상 메모리 기법을 사용해야 하는 것처럼 각각의 데이터를 동일한 데이터 블록에 보관하며 시작 offset 주소를 보관하여 필요한 경우 해당 블록의 offset 주소로 부터 데이터를 가지고 오는 방식을 택하면 된다.
즉, 하나의 파일 안에 여러 개의 작은 객체들을 보관하고 필요한 경우 해당 객체의 UUID를 통해서 offset 주소를 찾아 content size 크기 만큼의 끝 주소까지의 데이터를 가지고 온다면 데이터 블록을 효율적으로 사용 할 수 있다.

#### 내구성
**[디스크 데이터]**  
데이터는 어쨌든 어떠한 하나의 하드웨어에 보관이 된다. 이 때, AWS의 경우 각각의 AZ(Available Zone)에 여러 랙을 구성해놓고 있는데, 어떤 AZ 하나에 물리적인 이슈(자연재해 등)가 생겨서 해당 AZ 영역의 모든 컴퓨팅 시스템 및 하드웨어에 장애가 생기게 되면 파일을 가지고 올 수 없게 된다.  
따라서, 이를 방지하기 위해서는 데이터 또한 별도의 AZ에 복제 저장을 하도록 하며 **패리티 정보(Parity bit)**를 통해 장애가 생겼을 경우에 다시 해당 영역에 있는 데이터로 하여금 기존에 유실 된 데이터를 복제 할 수 있도록 한다.

**[메모리 데이터]**  
디스크의 있는 데이터가 복제가 가능하다고 하더라도, 때로는 메모리의 데이터가 훼손되는 경우도 발생한다. 이 경우에는 체크섬을 두어 해당 데이터가 온전한 상태인지를 확인하는데 체크섬 알고리즘을 통해 디스크에 있는 데이터의 원본 체크섬 데이터 결과를 알고 있다면 현재 메모리에 있는 체크섬 데이터와 알고리즘을 비교하여 훼손이 되었는지를 확인 할 수 있다. 하지만, 이 또한 우주 방사선 에너지로 인해서 트랜지스터의 스위치 전하 정보가 변경되게 되면 데이터가 변경 될 수 있다.

### 메타데이터 데이터 모델
- 메타데이터의 데이터 모델에서는 다음과 같은 질의를 수행 할 수 있어야 한다.
1. 객체 조회
2. 객체 삽입 또는 삭제
3. 같은 접두어를 갖는 버킷 내의 모든 객체 목록 확인

메타 데이터를 보관해야 할 사이즈가 매우 크기 떄문에 분산 데이터 저장소를 이용 할 필요가 있다. 단일 데이터베이스 테이블에 보관하기에는 양이 많다. 이 때, 유의할 점은 어떤 키를 샤딩의 기준으로 사용 할 것인지에 대한 기준인데 질의(1, 2)를 효율적으로 만족하기 위해서 bucket_name, object_name을 사용하여 샤딩을 진행한다. 이유는 object_id 혹은 bucket_id를 사용하여 데이터베이스의 테이블을 샤딩한다고 하면 샤딩하기에는 편하나 실제로 객체를 조회하고 객체를 삽입하고 삭제하는 경우 해당 키가 어떤 데이터베이스에 위치하는지를 찾은 뒤에 진행이 되기 때문이다.
클라이언트의 객체 탐색 과정은 URI를 통해서 이루어지고 해당 데이터는 bucket_name + object_name 이기 때문에 효율적인 탐색이 가능하다.

### 객체의 삭제
실제 객체를 삭제하는 경우에는 아예 데이터 자체를 삭제하는 것이 아니라 별도의 delete marker를 통하여 이전 버전의 데이터는 그대로 유지해두고 새로이 버전을 높여서 제거 된 상태(delete market = true)의 데이터를 저장해둔다.
하지만, 이럴 경우에 실제 데이터 보관소에는 실제로 제거되지 않았기 때문에 불 필요한 데이터가 많이 보관되게 되는데 이는 Garbage Collector 를 사용하여 compaction 매커니즘을 통해서 주기적으로 데이터를 제거한다.

## 💡 3. 전부 읽고 난 후기
- 실제로 데이터를 디스크에 어떻게 보관 할 것인지에 대해서 끊어져 있던 연결 고리를 몇 개 이을 수 있는 좋은 기회였다.
- 파일 시스템 혹은 블록 시스템을 좀 더 잘 이해하고 있었다면 해당 챕터를 더 즐겁게 읽을 수 있었을 것 같은 생각!?
- 여러 가지 문제 상황들에 대해서 발생 할 수 있는 여러 케이스를 접할 수 있었고, 이 과정에서 모르는 것들이 많이 나와서 배우기 좋은 시간이었다.

## ❓ 4. 특별히 궁금했던 부분
- 운영체제에서 디스크 I/O에 접근하여 실제 데이터를 가지고 오는 파일 시스템을 한 번 살펴봐야겠다(?) 운영체제 또한 별도의 소프트웨어로 구성이 되어 있고, 내부의 디스크는 여러 개의 프로세스와 스레드들이 접근 가능한 공유 저장소이다. 따라서, 여러 개의 프로세스와 스레드가 동시에 접근 할 수 있는 디스크 자체의 공유 자원에 대해서 동시에 쓰기 작업 혹은 읽기 작업을 진행 할 수 있는데 이럴 경우에 읽기 작업 자체에 lock을 걸어서 동시에 쓰는 것을 방지하는 것일까? 하는 의문이 들어요.
