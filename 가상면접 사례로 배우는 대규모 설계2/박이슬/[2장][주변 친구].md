## 📖 1. 목차를 읽기 전에 든 생각
- 링크드인의 1촌과 비슷한 기능일 것 같다. 주변 친구라면 2촌, 3촌까지 나타내는 기능인가?
- 만약 맞다면 DB 테이블은 어떻게 설계하는 것이 가장 효율적일까?

## 📝 2. 내용 정리
- 주변 친구는 인근의 친구 목록을 보여주는 서비스이다.
- 2단계: 개략적 설계안 제시 및 동의 구하기
  - 개략적 설계안
    - 공용 백엔드를 두어 모든 활성 상태 사용자의 위치 변화 내역을 수신하거나, 변경 내역을 전달한다.
  - 설계안
    - 로드밸런서는 분산 부하 역할을 한다.
    - RESTful API 서버는 친구 추가/삭제 등의 작업을 처리한다.
    - 웹소켓 서버는 친구 위치 정보 변경을 실시간에 가깝게 처리하는 서버 클러스터이다. 각 클라이언트를 그 중 한 대와 웹소켓 연결을 지속한다.
    - 레디스 위치 정보 캐시는 활성 상태 사용자의 가장 최근 위치 정보를 캐시한다. TTL을 두어 비활성 상태를 체크한다.
    - 사용자 DB는 사용자의 친구 관계 정보를 저장한다.
    - 위치 이동 이력 DB는 사용자의 위치 변동 이력을 보관한다.
    - 레디스 펍/섭 서버는 채널을 생성하여 사용자 위치 정보 변경 이벤트를 발행한다. 구독자는 해당 사용자 친구 각각과 연결된 웹소켓 연결 핸들러이다.
  - 데이터 모델
    - 위치 정보 저장에 DB를 사용하지 않는 이유는 사용자의 '현재 위치'만을 이용하기 때문이다. 죽 위치 정보를 영속적으로 보장할 필요가 없다.
    - 위치 이동 이력 DB는 막대한 쓰기 연산 부하를 감당할 수 있고, 수평적 규모 확장이 가능한 DB이다.
- 3단계: 상세 설계
  - 중요 구성요소별 규모 확장성
    - 레디스 펍/섭 서버의 병목은 메모리가 아니라 CPU 사용량이며, 추정하면 140대(보수적) 정도 필요하다.
    - 분산 레디스 펍/섭 서버 클러스터
      - 서비스 탐색(service discovery) 컴포넌트를 도입하여 문제를 풀 수 있다.
      - 값에는 활성 상태의 모든 레디스 펍/섭 서버로 구성된 해시 링을 보관한다.
      - 웹 소켓 서버는 해시 링을 참조하여 메시지를 발행할 레디스 펍/섭 서버를 선정한다.
    - 레디스 펍/섭 서버 클러스터의 규모 확장 고려사항
      - 유상태 서버 클러스터이다.
      - 클러스터 크기를 조정할 때는 새로운 해시 링을 통해 새로운 내용으로 갱신한다.
    - 운영 고려사항
      - 펍/섭 서버에 장애가 발생하면 서비스 탐색 컴포넌트의 해시 링 키에 매달린 값을 갱신하여 장애가 발생한 노드를 대기 중인 노드와 교체한다. 교체 사실은 모든 웹소켓 서버에 통지되고, 각 웹소켓 서버는 실행 중인 연결 핸들러에ㅔ 새 펍/섭 채널을 다시 구독하도록 알린다.
  - 친구 추가/삭제
    - 친구 추가/삭제 시 호출될 콜백을 앱에 등록해준다. 콜백이 호출되면 웹소켓 서버로 구독/구독 취소 메시지를 보낸다.
  - 친구가 많은 사용자
    - 많은 친구를 둔 사용자의 채널이 존재하는 펍/섭 서버의 경우에는 조금 더 많은 부하를 감당하게 될 수 있다. 하지만 서버가 많고 헤비 유저들 채널이 분산된다는 점을 감안하면 부담을 줄 일을 없을 것이다.
  - 주변의 임의 사용자
    - 정보 공유에 동의한 주변 사용자들을 무작위로 보여줄 수 있다고 해보자.
    - 지오해시에 따라 구축된 펍/섭 채널 풀을 두는 것이다.
    - 지오해시 격자마다 채널을 만들어두고 해당 격자 내 모든 사용자는 해당 격자에 할당된 채널을 구독한다.

## 💡 3. 전부 읽고 난 후기
- 지금까지 생각해본적 없는 시스템이어서 읽으면서 되게 흥미로웠다.

## ❓ 4. 특별히 궁금했던 부분
- 토스 앱을 켰을 때, 주변에 토스 앱을 켠 사람이 있다고 알림이 오는데 이것도 책에서 설명한 내용처럼 구현되어 있을지 궁금하다.
