## 📖 1. 목차를 읽기 전에 든 생각
- 광고 클릭 이벤트 집계는 동시성 처리가 중요할 것 같은데, 과연 동시성 처리를 하면서까지 보장해야하는 수인가? 어느 정도 손실은 괜찮지 않을까?
- 만약 광고 클릭 이벤트로 선착순 쿠폰 등을 준다면 동시성 처리가 중요할 것 같다.
- 광고 클릭 이벤트 집계는 큐를 사용할 것 같은데, 해당 책에서 어떤 큐를 사용할 지 궁금하다.

## 📝 2. 내용 정리
### 2단계: 개략적 설계안 제시 및 동의 구하기
#### 데이터 모델
- 원시 데이터와 집계 결과 데이터 둘 다 저장할 것을 추천
  - 원시 데이터 저장
    - 문제 발생 시 디버깅 용도
    - 데이터 손상 시 다시 집계
    - 백업 데이터로 활용 -> 오래된 데이터는 냉동 저장소로 옮겨서 비용 절담
  - 집계 결과 데이터
    - 효율적인 질의ㅣ
    - 활성 데이터 구실, 질의 성능을 높이기 위해
- 올바른 DB 선택 기준
  1. 데이터는 어떤 모습인가?
  2. 작업 흐름이 읽기 중심인가? 쓰기 중심인가? 아니면 둘 다인가?
  3. 트랙잭션을 지원해야 하는가?
  4. 질의 과정에서 온라인 분석 처리(OLAP) 함수를 많이 사용해야 하는가?
- DB 선택
  - 원시 데이터는 쓰기 연산 중심, 집계 데이터는 시계열 데이터이며 읽기/쓰기 연산 둘 다
  - 카산드라 활용

#### 개략적 설계
#### 비동기 처리
- 트래픽이 갑자기 증가하여 발생하는 이벤트 수가 소비자 처리 용량을 넘어서는 경우 예기치 않은 문제 발생
- 카프카 같은 메시지 큐를 도입하여 생상자와 소비자 결합 끊기 -> 각각 독립적 규모 확장 가능
- 메시지 큐 1: 로그 모니터 <-> 원시 데이터 DB
- 메시지 큐 2: 데이터 집계 서비스 <-> 집계 결과 DB
  - 정확하게 한 번 데이터를 처리하기 위해 메시지 큐 도입

#### 집계 서비스
- 맵리듀스 프레임워크 사용
- 맵 노드
  - 데이터 출처에서 읽은 데이터를 필터링하고 반환하는 역할
  - 입력 데이터를 정리하거나 정규화해야 하는 경우에 필요
  - 데이터가 생성되는 방식에 대한 제어권이 없는 경우 동일한 ad_id를 갖는 이벤트가 서로 다른 카프카 파티션에 입력될 수 있음
- 집계 노드
  - 리듀스 프로세스 일부
  - ad_id별 광고 클릭 이벤트 수를 매 분 메모리에서 집계
- 리듀스 노드
  - 모든 '집계' 노드가 산출한 결과를 최종 결과로 축약
  - 

### 3단계: 상세 설계
#### 스트리밍 vs 일괄 처리
- 스트림 처리는 데이터를 오는 대로 처리하고 거의 실시간으로 집계된 결과를 생성하는 데 사용
- 일괄 처리는 이력 데이터를 백업하기 위해 활용
- 람다: 일괄 및 스트리밍 처리 경로를 동시 지원하는 시스템 아키텍처
  - 두 가지 처리 경로를 지원하므로 유지 관리해야할 코드가 두 번
- 카파: 처리 경로를 하나로 결합하여 위 문제를 해결 (본 시스템은 카파 아키텍처를 따름)
  - 단일 스트림 처리 엔진을 사용하여 실시간 데이터 처리 및 끊임없는 데이터 재처리(일괄) 문제 해결

##### 데이터 재계산
- 이력 데이터 재처리
- 버그 발생 시점부터 원시 데이터를 다시 읽어 집계 데이터를 재계산하고 고침
- 실시간 데이터 처리 과정이 과거 데이터 재처리 프로세스와 간섭하는 일을 막기 위해 전용 집계 서비스를 둔다.
- 집계 결과는 두 번째 메시지 큐로 전송되어 집계 결과 DB에 반영된다.

#### 시간
- 이벤트 발생 시각을 집계에 사용
- 텀블링 윈도우와 워터마크(집계 윈도의 확장)를 사용
  - 워터마크를 사용하면 데이터의 정확도는 높아지지만 대기 시간이 늘어나 전반적인 지연 시간이 늘어남

#### 집계 윈도
- 텀블링 윈도는 시간을 같은 크기의 겹치지 않은 구간으로 분할 -> 매 분 발생한 클릭 이벤트를 집계하기 적합
- 슬라이딩 윈도는 데이터 스트림을 미끄러져 나아가면서 같은 시간 구간 안에 이벤트 집계 -> 지난 M분간 가장 많이 클릭된 상위 N개 광고 알아내기 적합

#### 전달 보장
- 이벤트의 중복 처리를 어떻게 피할 수 있는가?
- 모든 이벤트의 처리는 어떻게 보장할 수 있는가?

##### 데이터 중복 제거
- 중복 데이터 발생 -> 서버 장애: 집계 도중 집계 서비스 노드에서 장애가 발생, 업스트림 서비스가 이벤트 메시지에 대해 응답을 받지 못해서 같은 이벤트가 다시 전송되어 재차 집계
1. 집계 서비스 노드 -> 업스트림(카프카): 이벤트 수집 (폴)
2. 업스트림(카프카) -> 집계 서비스 노드: 오프셋 100부터 소비
3.1. 집계 서비스 노드 -> S3: 오프셋 확인
3. 집계 서비스 노드: 100부터 110까지 이벤트 집계
-----분산 트랜잭션 시작------
4. 집계 서비스 노드 -> 다운스트림(카프카): 집계 결과 전송
5. 집계 서비스 노드 -> S3: 오프셋 저장
6. 다운스트림(카프카) -> 집계 서비스 노드: 수신 확인 응답 전송
-----분산 트랜잭션 종료------
7. 집계 서비스 노드 -> 업스트림(카프카): 새 오프셋 110 응답

#### 시스템 규모 확장
##### 메시지 큐의 규모 확장
- 소비자 확장은 그룹 내의 재조정 메커니즘을 통해 규모를 쉽게 조정할 수 있다. 수백 개 소비자가 있는 경우는 재조정 작업 시간이 길어지므로 시스템 사용량이 많지 않은 시간에 실행하는 것이 좋다.
- 브로커 파티션 수는 사전에 충분한 파티션을 확보하여 상용 환경에서 파티션 수가 동적으로 늘어나는 일은 피하는 것이 좋다.
  - 파티션 수가 변하면 같은 ad_id를 같는 이벤트가 다른 파티션에 기록되는 일이 생길 수 있기 때문
- 브로커 토픽의 물리적 샤딩을 통해 시스템 처리 대역폭을 높일 수 있고 소비자 그룹의 재조정 시간도 단축된다. 복잡성이 증가하고 유지 관리 비용이 늘어난다.

##### 집계 서버의 규모 확장
- 노드 추가/삭제를 통해 수평적 조정 가능
- 처리 대역폭을 높이려면
  - 방안1: ad_id마다 별도의 처리 스레드 두기
  - 방안2: 집계 서비스 노드를 아파치 하둡 같은 자원 공급자에 배포하여 다중 프로세싱 활용
  - 방안1이 구현하기 쉽지만 실제로는 방안2 많이 사용 -> 컴퓨팅 자원을 추가하여 시스템 규모를 확장할 수 있기 때문

##### DB의 규모 확장
- 카산드라는 안정 해시와 유사한 방식으로 수평적인 규모 확장 지원
- 클러스터에 새 노드를 추가하면 가상 노드 간의 균형은 자동으로 다시 조정되므로, 수동으로 샤딩을 조정하는 과정은 필요하지 않음

#### 핫스팟
- 어떤 집계 노드는 다른 노드보다 더 많은 광고 클릭 이벤트를 수신할 수 있음 -> 서버 과부하 문제 발생
- 자원 관리자에게 추가 자원을 신청하여 노드에 과부하가 걸리지 않도록 한다.

#### 결함 내성
- 업스트림 오프셋 뿐만 아니라 지난 M분간 가장 많이 클릭된 광고 N개 같은 데이터도 시스템의 상태의 일부다.
- 시스템의 상태를 스냅샷을 이용하여 보관하고, 집계 서비스를 복구한다.

#### 데이터 모니터링 및 정확성
- 지속적 모니터링: 지연 시간, 메시지 큐 크기, 집계 노드의 시스템 자원
- 조정: 다양한 데이터를 비교하여 데이터 무결성 보증 기법
  - 각 파티션에 기록된 클릭 이벤트를 이벤트 발생 시각에 따라 정렬한 결과를 일괄 처리하여 만들어 낸 다음, 실시간 집계 결과와 비교

## 💡 3. 전부 읽고 난 후기
- 맵리듀스 프레임워크, 스타 스키마, 람다(일괄 및 스트리밍 처리 경로를 동시 지원하는 시스템 아키텍처) 등 새로운 개념을 알게 되었다.
- 217P 그림 6.20에 오타 있음 (7번 새 오프셋 110 응답)

## ❓ 4. 특별히 궁금했던 부분
- 맵리듀스 프레임워크는 어떤 것인가?
  - https://ko.wikipedia.org/wiki/%EB%A7%B5%EB%A6%AC%EB%93%80%EC%8A%A4
  - https://smart.science.go.kr/upload_data/subject/bigdata/pdf/B_E_09.pdf
- 윈도우 종류와 특징
  - https://velog.io/@haron/kafka-streams
